{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting symspellpy\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/0b/2daa14bf1ed649fff0d072b2e51ae98d8b45cae6cf8fdda41be01ce6c289/symspellpy-6.5.2-py3-none-any.whl (2.6MB)\n",
      "Requirement already satisfied: numpy>=1.13.1 in c:\\users\\aiswarriya\\anaconda3\\lib\\site-packages (from symspellpy) (1.17.2)\n",
      "Installing collected packages: symspellpy\n",
      "Successfully installed symspellpy-6.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install symspellpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where is the love he had dated for much of the past who couldn't read in six grade and inspired him\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity  # import the module\n",
    "\n",
    "def main():\n",
    "    # maximum edit distance per dictionary precalculation\n",
    "    max_edit_distance_dictionary = 5\n",
    "    prefix_length = 7\n",
    "    # create object\n",
    "    sym_spell = SymSpell(max_edit_distance_dictionary, prefix_length)\n",
    "    # load dictionary\n",
    "    dictionary_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "    bigram_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
    "    # term_index is the column of the term and count_index is the\n",
    "    # column of the term frequency\n",
    "    if not sym_spell.load_dictionary(dictionary_path, term_index=0,\n",
    "                                     count_index=1):\n",
    "        print(\"Dictionary file not found\")\n",
    "        return\n",
    "    if not sym_spell.load_bigram_dictionary(bigram_path, term_index=0,\n",
    "                                            count_index=2):\n",
    "        print(\"Bigram dictionary file not found\")\n",
    "        return\n",
    "\n",
    "    # lookup suggestions for single-word input strings\n",
    "    input_term = \"memebers\"  # misspelling of \"members\"\n",
    "    # max edit distance per lookup\n",
    "    # (max_edit_distance_lookup <= max_edit_distance_dictionary)\n",
    "    max_edit_distance_lookup = 2\n",
    "    suggestion_verbosity = Verbosity.CLOSEST  # TOP, CLOSEST, ALL\n",
    "    suggestions = sym_spell.lookup(input_term, suggestion_verbosity,\n",
    "                                   max_edit_distance_lookup)\n",
    "    # display suggestion term, term frequency, and edit distance\n",
    "    #for suggestion in suggestions:\n",
    "    #    print(\"{}, {}, {}\".format(suggestion.term, suggestion.distance,\n",
    "     #                             suggestion.count))\n",
    "\n",
    "    # lookup suggestions for multi-word input strings (supports compound\n",
    "    # splitting & merging)\n",
    "    input_term = (\"whereis th elove hehad dated forImuch of thepast who \"\n",
    "                  \"couqdn'tread in sixtgrade and ins pired him\")\n",
    "    # max edit distance per lookup (per single word, not per whole input string)\n",
    "    max_edit_distance_lookup = 2\n",
    "    suggestions = sym_spell.lookup_compound(input_term,\n",
    "                                            max_edit_distance_lookup)\n",
    "    # display suggestion term, edit distance, and term frequency\n",
    "    for suggestion in suggestions:\n",
    "        print(\"{}\".format(suggestion.term))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where is the love he had dated for much of the past who couldn't read in six grade and inspired him\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cleansing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-da937a1c7c44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m    \u001b[1;31m# cleansing(text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-da937a1c7c44>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuggestion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m    \u001b[1;31m#calling the next function cleansing for the further process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mcleansing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleansing' is not defined"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity  # import the module\n",
    "global text\n",
    "\n",
    "def main():\n",
    "    # defining the the number of edit distance dictionary and the prefix lengt for the init signature of spellcheck\n",
    "    max_edit_distance_dictionary = 2\n",
    "    prefix_length = 3\n",
    "    # Creating a object for the purpose for spellchecl implementation \n",
    "    sym_spell = SymSpell(max_edit_distance_dictionary, prefix_length)\n",
    "    sym_spell1 = SymSpell()\n",
    "    # Loading the types of dictionary one is dictinary_path and bigram_path for the purpose of frequency \n",
    "    dictionary_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "    bigram_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
    "    \n",
    "    if not sym_spell.load_dictionary(dictionary_path, term_index=0,\n",
    "                                     count_index=1):\n",
    "        print(\"Dictionary file not found\")\n",
    "        return\n",
    "    if not sym_spell.load_bigram_dictionary(bigram_path, term_index=0,\n",
    "                                            count_index=2):\n",
    "        print(\"Bigram dictionary file not found\")\n",
    "        return\n",
    "\n",
    " # Defining the static input term for the process of spell checking \n",
    "    input_term = (\"whereis th elove hehad dated forImuch of thepast who \"\n",
    "                  \"couqdn'tread in sixtgrade and ins pired him\")\n",
    " # max edit distance per lookup (per single word, not per whole input string)\n",
    "    max_edit_distance_lookup = 2\n",
    "    suggestions = sym_spell.lookup_compound(input_term,\n",
    "                                            max_edit_distance_lookup)\n",
    " # display suggestion term, edit distance, and term frequency\n",
    "    for suggestion in suggestions:\n",
    "        print(\"{}\".format(suggestion.term))\n",
    "    text = suggestion.term\n",
    "   #calling the next function cleansing for the further process\n",
    "    cleansing(text)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "   # cleansing(text)\n",
    "    \n",
    "    \n",
    "def cleansing(text):\n",
    "    import spacy\n",
    "    from spacy.lang.en import English\n",
    "    spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    parser = English()\n",
    "    nlp = spacy.load('en_core_web_sm',disable='NER')\n",
    "    nlp.max_length = 30\n",
    "    df= text\n",
    "    #print(df)\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    mytokens = [ word for word in df if word not in stopwords]\n",
    "    print (mytokens)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
